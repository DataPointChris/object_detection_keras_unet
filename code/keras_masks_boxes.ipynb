{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://www.kaggle.com/christofhenkel/keras-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the plaidml backend\n",
    "## DO THIS BEFORE IMPORTING KERAS OR TENSOR TO USE PLAIDML\n",
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "\n",
    "# Help MacOS be able to use Keras\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets rid of the processor warning.\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Input, BatchNormalization, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, concatenate, Concatenate, Conv2DTranspose, UpSampling2D\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from tqdm.keras import TqdmCallback\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL PARAMS #\n",
    "\n",
    "TRAIN_IMAGE_DIR = '../images/network_training/build/0/'\n",
    "TRAIN_MASK_DIR = '../images/network_training/mask/0/'\n",
    "TEST_IMAGE_DIR = '../images/network_training/test/0/'\n",
    "\n",
    "# images to split and feed into the generator\n",
    "# decrease this number if running out of GPU memory\n",
    "# works with 4 on 11GB GPU\n",
    "images_per_batch = 4\n",
    "\n",
    "# val split from training set\n",
    "train_val_split_size = .1\n",
    "\n",
    "\n",
    "# IMAGE SPLITTER PARAMS #\n",
    "\n",
    "split_rows = 20\n",
    "split_cols = 20\n",
    "img_resize_width = 4800\n",
    "img_resize_height = 4800\n",
    "\n",
    "\n",
    "# MODEL PARAMS #\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 4\n",
    "pretrained_model = False\n",
    "model_path = '../data/testing_model.h5'\n",
    "plot_epoch_val_images = False\n",
    "early_stop = EarlyStopping(patience=5, verbose=1)\n",
    "check_point = ModelCheckpoint(f'../data/{model_name}.hdf5',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir_images = glob.glob(TRAIN_IMAGE_DIR + '*')\n",
    "train_filenames = [os.path.basename(x) for x in train_names]\n",
    "\n",
    "test_dir_images = glob.glob(TEST_IMAGE_DIR + '*')\n",
    "test_filenames = [os.path.basename(x) for x in test_dir_images]\n",
    "\n",
    "# create batch sets of 'images_per_batch' size\n",
    "training_sets = [train_filenames[i :i + images_per_batch] for i in range(0,len(train_filenames),images_per_batch)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_and_mem(array):\n",
    "    print(f'Shape: {array.shape}')\n",
    "    print(f'Size: {round(array.itemsize * X_test.size / 1024 / 1024 / 1024, 3)} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def image_splitter(image, num_col_splits, num_row_splits, resize=False, resize_width=None, resize_height=None):\n",
    "    \"\"\"\n",
    "    Splits an image into 'num_col_splits' X 'num_row_splits'\n",
    "    Resize by setting resize=True and specifying 'resize_width' and 'resize_height'\n",
    "    Returns array of images arranged from left -> right, top -> bottom\n",
    "    \"\"\"\n",
    "    if resize:\n",
    "        image = skimage.transform.resize(image, (resize_width, resize_height))\n",
    "    \n",
    "    width = image.shape[0] \n",
    "    height = image.shape[1]\n",
    "    imglist = []\n",
    "\n",
    "    for startpoint in np.linspace(0,width,num_col_splits, endpoint=False):\n",
    "        endpoint=startpoint + (width / num_col_splits)\n",
    "\n",
    "        for startp2 in np.linspace(0,height,num_row_splits, endpoint=False):\n",
    "            endp2=startp2 + (height / num_row_splits)\n",
    "\n",
    "            imglist.append(image[int(startp2):int(endp2), int(startpoint):int(endpoint)]\n",
    "                        )\n",
    "    return np.array(imglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_checker(original, ground_truth):\n",
    "    \n",
    "    for _ in range(4):\n",
    "        ix = np.random.randint(0, original.shape[0])\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 24))\n",
    "\n",
    "        ax1.set_title('Original')\n",
    "        ax1.imshow(original[ix])\n",
    "        ax1.axis('off')\n",
    "\n",
    "        ax2.set_title('Ground Truth')\n",
    "        ax2.imshow(np.squeeze(ground_truth[ix]))\n",
    "        ax2.axis('off')    \n",
    "\n",
    "        plt.subplots_adjust(wspace=.3, hspace=.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(pretrained_model=False, model_name=None, batch_number=batch_number):\n",
    "    '''\n",
    "    Creates a new U-Net model\n",
    "    '''\n",
    "    if pretrained_model or batch_number > 0:\n",
    "        print('Loading Trained Model')\n",
    "        model = load_model(model_path)\n",
    "        print()\n",
    "    else:\n",
    "        print('Creating New Model')\n",
    "        print()\n",
    "        inputs = Input((X_train.shape[1], X_train.shape[2], 3))\n",
    "        s = Lambda(lambda x: x) (inputs) # removed / 255\n",
    "\n",
    "        c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "        c1 = Dropout(0.1) (c1)\n",
    "        c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "        p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "        c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "        c2 = Dropout(0.1) (c2)\n",
    "        c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "        p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "        c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "        c3 = Dropout(0.2) (c3)\n",
    "        c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "        p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "        c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "        c4 = Dropout(0.2) (c4)\n",
    "        c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "        p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "        c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "        c5 = Dropout(0.3) (c5)\n",
    "        c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "        u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "        u6 = concatenate([u6, c4])\n",
    "        c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "        c6 = Dropout(0.2) (c6)\n",
    "        c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "        u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "        u7 = concatenate([u7, c3])\n",
    "        c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "        c7 = Dropout(0.2) (c7)\n",
    "        c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "        u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "        u8 = concatenate([u8, c2])\n",
    "        c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "        c8 = Dropout(0.1) (c8)\n",
    "        c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "        u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "        u9 = concatenate([u9, c1], axis=3)\n",
    "        c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "        c9 = Dropout(0.1) (c9)\n",
    "        c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "        outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "        model = Model(inputs=[inputs], outputs=[outputs])\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(original, predicted, predicted_mask, ground_truth=None, repeat=False):\n",
    "\n",
    "    ncols_calc = 3\n",
    "    if ground_truth is not None:\n",
    "        ncols_calc = 4\n",
    "        \n",
    "    \n",
    "    for i in range(4):\n",
    "        if repeat:\n",
    "            ix = i\n",
    "        else:\n",
    "            ix = np.random.randint(0, predicted.shape[0])\n",
    "            \n",
    "        fig, ax = plt.subplots(ncols=ncols_calc, figsize=(ncols_calc*5, 24))\n",
    "\n",
    "        ax[0].set_title('Original')\n",
    "        ax[0].imshow(original[ix])\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].set_title('Predicted')\n",
    "        ax[1].imshow(np.squeeze(predicted[ix]))\n",
    "        ax[1].axis('off')    \n",
    "\n",
    "        ax[2].set_title('Predicted Mask')\n",
    "        ax[2].imshow(np.squeeze(predicted_mask[ix]))\n",
    "        ax[2].axis('off')\n",
    "        \n",
    "        if ground_truth is not None:\n",
    "            ax[3].set_title('Ground Truth')\n",
    "            ax[3].imshow(np.squeeze(ground_truth[ix]))\n",
    "            ax[3].axis('off')\n",
    "\n",
    "        plt.subplots_adjust(wspace=.3, hspace=.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Process Images and Train on Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_number, current_train_set in enumerate(training_sets):\n",
    "    \n",
    "    print()\n",
    "    print('********************')\n",
    "    print(f'Batch Number {batch_number+1} of {len(training_sets)}')\n",
    "    print('********************')\n",
    "    print()\n",
    "    print('Loading Images:')\n",
    "    print()\n",
    "\n",
    "    # Load each image in current_train set in as uint8\n",
    "    # Split image using image splitter\n",
    "    # VStack the arrays together and normalize using /255\n",
    "    X = [np.array(\n",
    "            image_splitter(\n",
    "                skimage.io.imread(TRAIN_IMAGE_DIR + process_img).astype(np.uint8), \n",
    "                num_col_splits=split_cols, \n",
    "                num_row_splits=split_rows,\n",
    "                resize=True,\n",
    "                resize_height=img_resize_height,\n",
    "                resize_width=img_resize_width\n",
    "            )\n",
    "        ) for process_img in tqdm(current_train_set)]\n",
    "\n",
    "    X = (np.vstack(X)/255).astype(np.float16)\n",
    "\n",
    "    print()\n",
    "    shape_and_mem(X)\n",
    "    \n",
    "    print()\n",
    "    print('Loading Masks:')\n",
    "    print()\n",
    "\n",
    "    y = [np.array(\n",
    "            image_splitter(\n",
    "                skimage.io.imread(TRAIN_MASK_DIR + process_img, as_gray=True).astype(np.uint8),\n",
    "                num_row_splits=split_rows,\n",
    "                resize=True,\n",
    "                resize_height=img_resize_height,\n",
    "                resize_width=img_resize_width\n",
    "            )\n",
    "        ) for process_img in tqdm(current_train_set)]\n",
    "\n",
    "    y = (np.vstack(y)/255).astype(np.float16)\n",
    "    \n",
    "    # Expand dims because it's grayscale\n",
    "    y = np.expand_dims(y, axis=3)\n",
    "    \n",
    "    print()\n",
    "    shape_and_mem(y)\n",
    "    print()\n",
    "\n",
    "    # Test if images look okay\n",
    "\n",
    "    # print()\n",
    "    # print('Checking images')\n",
    "    # image_checker(original=X, ground_truth=y)\n",
    "\n",
    "    print('Train / Val Splitting')\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=23, test_size =train_val_split_size)\n",
    "    print()\n",
    "    print('X_train')\n",
    "    shape_and_mem(X_train)\n",
    "    print()\n",
    "    print('y_train')\n",
    "    shape_and_mem(y_train)\n",
    "\n",
    "    make_model(pretrained_model=pretrained_model, model_name=model_name, batch_number=batch_number)\n",
    "\n",
    "    print()\n",
    "    print('Fitting Model')\n",
    "    print()\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "\n",
    "    # datagen = ImageDataGenerator(\n",
    "    #                             featurewise_center=False,\n",
    "    #                             featurewise_std_normalization=False\n",
    "    #                             )\n",
    "\n",
    "    # NOT using this at the moment ########################################################\n",
    "    # datagen.fit(X_train)\n",
    "\n",
    "    # Use datagen to split data into smaller batches for training.\n",
    "\n",
    "    # history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "    #                     epochs=epochs, \n",
    "    #                     validation_data=(X_val, y_val),\n",
    "    #                     verbose=1, \n",
    "    #                     steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "    #                     validation_steps=(X_train.shape[0] // batch_size) * train_val_split_size,\n",
    "    #                     callbacks=[early_stop, check_point])\n",
    "\n",
    "    #####################################################################################\n",
    "\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs, \n",
    "                        validation_data=(X_val, y_val),\n",
    "                        verbose=1, \n",
    "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                        validation_steps=(X_train.shape[0] // batch_size) * train_val_split_size,\n",
    "                        callbacks=[early_stop, check_point])\n",
    "    \n",
    "    if plot_epoch_val_images:\n",
    "        plot_predictions(original=X_val, predicted=X_val_pred, \n",
    "                         predicted_mask=X_val_pred_mask, ground_truth=y_val, repeat=True)\n",
    "    \n",
    "    print('***###!!! DONE !!!###***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_val_pred = model.predict(X_val, verbose=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x=X_val, y=y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple threshold to change to 1/0, mask\n",
    "X_val_pred_mask = (X_val_pred > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(original=X_val, predicted=X_val_pred, predicted_mask=X_val_pred_mask, ground_truth=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.jeremyjordan.me/evaluating-image-segmentation-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [np.array(\n",
    "            image_splitter(\n",
    "                skimage.io.imread(TEST_IMAGE_DIR + p),\n",
    "                num_col_splits=split_cols,\n",
    "                num_row_splits=split_rows,\n",
    "                resize=True,\n",
    "                resize_height=img_height,\n",
    "                resize_width=img_width\n",
    "            )\n",
    "        ) for p in tqdm(test_filenames[:10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (np.vstack(test_split_images)/255).astype(np.float32)\n",
    "\n",
    "shape_and_mem(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def image_tester(original):\n",
    "    \n",
    "    for _ in range(4):\n",
    "        ix = np.random.randint(0, original.shape[0])\n",
    "        fig, ax = plt.subplots(figsize=(10, 24))\n",
    "\n",
    "        ax.set_title('Original')\n",
    "        ax.imshow(original[ix])\n",
    "        ax.axis('off')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_tester(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_test_pred = model.predict(X_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_and_mem(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pred_mask = (y_pred > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_predictions(original=X_test, predicted=X_test_pred, predicted_mask=X_test_pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = cv2.bitwise_and(test_split[0], test_split[0], mask=prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
