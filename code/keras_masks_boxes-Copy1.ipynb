{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://www.kaggle.com/christofhenkel/keras-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# CURRENTLY WORKING WITH TENSORFLOW\n",
    "# \n",
    "# PRIORITIES:\n",
    "# 1. refactor code to better groupings\n",
    "# 2. where do the functions go\n",
    "# 3. grab validation data\n",
    "#\n",
    "#\n",
    "# If you are a potential EMPLOYER looking over my code, THANK YOU!\n",
    "# I love to hear comments and critiques about being a better programmer,\n",
    "# data engineer, and data scientist.  \n",
    "# If you found this code useful or learned something, YAY!\n",
    "# \n",
    "# LinkedIn: /in/chris-birch\n",
    "# Portfolio: www.datapointchris.com/portfolio\n",
    "# Website: www.datapointchris.com\n",
    "#\n",
    "#########################################################################\n",
    "\n",
    "# # ================================================ FOR RUNNING ON THE MACBOOK PRO\n",
    "\n",
    "# # DONT LEAVE COMMENTED CODE IN THE FINAL CODE. WOULD HAVE TO FIND OS IF NECESSARY BUT NOT\n",
    "\n",
    "# ## DO THIS BEFORE IMPORTING KERAS OR TENSOR TO USE PLAIDML\n",
    "# import plaidml.keras\n",
    "# plaidml.keras.install_backend()\n",
    "\n",
    "# # Help MacOS be able to use Keras\n",
    "# import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "# # Gets rid of the processor warning.\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Input, BatchNormalization, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, concatenate, Concatenate, Conv2DTranspose, UpSampling2D\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from tqdm.keras import TqdmCallback\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import skimage.io\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# =========================================================================Parameters, paths and variables\n",
    "# =========================================================================Parameters, paths and variables\n",
    "# =========================================================================Parameters, paths and variables\n",
    "# hard coded for now\n",
    "\n",
    "train_image_dir = '../images/network_training/build/0/'\n",
    "train_mask_dir = '../images/network_training/mask/0/'\n",
    "test_image_dir = '../images/network_training/test/0/'\n",
    "data_dir = '../data/'\n",
    "\n",
    "train_images = glob.glob(train_image_dir + '*')\n",
    "train_filenames = [os.path.basename(x) for x in train_images]\n",
    "\n",
    "test_images = glob.glob(test_image_dir + '*')\n",
    "test_filenames = [os.path.basename(x) for x in test_images]\n",
    "\n",
    "\n",
    "# decrease this number if running out of memory\n",
    "# works with 4 on 11GB GPU\n",
    "images_per_batch = 4\n",
    "\n",
    "# val split from training set\n",
    "train_val_split_size = .1\n",
    "\n",
    "seed = 77\n",
    "\n",
    "\n",
    "# IMAGE SPLITTER PARAMS #\n",
    "\n",
    "split_rows = 20\n",
    "split_cols = 20\n",
    "resize = True\n",
    "image_resize_width = 4800\n",
    "image_resize_height = 4800\n",
    "\n",
    "\n",
    "# MODEL PARAMS #\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 1\n",
    "pretrained_model = False\n",
    "model_name = 'datagenmodel'\n",
    "model_path = os.path.join(data_dir, model_name + '.h5')\n",
    "plot_epoch_val_images = True\n",
    "data_augmentation = False\n",
    "early_stop = EarlyStopping(patience=5, verbose=1)\n",
    "check_point = ModelCheckpoint(os.path.join(data_dir, model_name + '.hdf5'),\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "datagen_args = dict(featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                             samplewise_center=False,  # set each sample mean to 0\n",
    "                             featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                             samplewise_std_normalization=False,  # divide each input by its std\n",
    "                             zca_whitening=False,  # apply ZCA whitening\n",
    "                             zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "                             # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                             rotation_range=0,\n",
    "                             # randomly shift images horizontally (fraction of total width)\n",
    "                             width_shift_range=0.1,\n",
    "                             # randomly shift images vertically (fraction of total height)\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.,  # set range for random shear\n",
    "                             zoom_range=0.,  # set range for random zoom\n",
    "                             channel_shift_range=0.,  # set range for random channel shifts\n",
    "                             # set mode for filling points outside the input boundaries\n",
    "                             fill_mode='nearest',\n",
    "                             cval=0.,  # value used for fill_mode = \"constant\"\n",
    "                             horizontal_flip=True,  # randomly flip images\n",
    "                             vertical_flip=False,  # randomly flip images\n",
    "                             # set rescaling factor (applied before any other transformation)\n",
    "                             rescale=None,\n",
    "                             # set function that will be applied on each input\n",
    "                             preprocessing_function=None,\n",
    "                             # image data format, either \"channels_first\" or \"channels_last\"\n",
    "                             data_format='channels_last',\n",
    "                             # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "                             validation_split=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValPlotCallback(Callback):\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print('VALIDATION IMAGES')\n",
    "        X_val_pred = model.predict(X_val, verbose=1, batch_size=batch_size)\n",
    "        X_val_pred_mask = (X_val_pred > 0.5).astype(np.uint8)\n",
    "        plot_predictions(original=X_val,\n",
    "                         predicted=X_val_pred,\n",
    "                         predicted_mask=X_val_pred_mask,\n",
    "                         ground_truth=y_val,\n",
    "                         repeat=True)\n",
    "\n",
    "def load_image_as_array(image_name, image_dir, gray=False, resize=False):\n",
    "    \"\"\"\n",
    "    Loads and splits an image\n",
    "    Returns numpy array\n",
    "    \"\"\"\n",
    "    if gray is False:\n",
    "        image = cv2.imread(image_dir + image_name).astype(np.uint8)\n",
    "    else:\n",
    "        image = cv2.imread(image_dir + image_name, 0).astype(np.uint8)\n",
    "\n",
    "    image_as_array = image_splitter(image,\n",
    "                                 num_col_splits=split_cols,\n",
    "                                 num_row_splits=split_rows,\n",
    "                                 resize=resize,\n",
    "                                 resize_height=image_resize_height,\n",
    "                                 resize_width=image_resize_width)\n",
    "\n",
    "    return image_as_array\n",
    "\n",
    "def shape_and_mem(array):\n",
    "    \"\"\"Prints the shape and memory size of an array\"\"\"\n",
    "    print(f'Shape: {array.shape}')\n",
    "    print(f'Size: {round(array.itemsize * array.size / 1024 / 1024 / 1024, 3)} GB')\n",
    "\n",
    "def image_splitter(image, num_col_splits, num_row_splits, resize=False, resize_width=None, resize_height=None):\n",
    "    \"\"\"\n",
    "    Splits an image into 'num_col_splits' X 'num_row_splits'\n",
    "    Resize by setting resize=True and specifying 'resize_width' and 'resize_height'\n",
    "    Returns array of images arranged from left -> right, top -> bottom\n",
    "    \"\"\"\n",
    "    if resize:\n",
    "        image = cv2.resize(image, (resize_width, resize_height))\n",
    "    \n",
    "    width = image.shape[0] \n",
    "    height = image.shape[1]\n",
    "    imglist = []\n",
    "\n",
    "    for startpoint in np.linspace(0,width,num_col_splits, endpoint=False):\n",
    "        endpoint=startpoint + (width / num_col_splits)\n",
    "\n",
    "        for startp2 in np.linspace(0,height,num_row_splits, endpoint=False):\n",
    "            endp2=startp2 + (height / num_row_splits)\n",
    "\n",
    "            imglist.append(image[int(startp2):int(endp2), int(startpoint):int(endpoint)]\n",
    "                        )\n",
    "    return np.array(imglist)\n",
    "\n",
    "def image_tester(original):\n",
    "    \"\"\"Shows original images in array\"\"\"\n",
    "    for _ in range(4):\n",
    "        ix = np.random.randint(0, original.shape[0])\n",
    "        fig, ax = plt.subplots(figsize=(10, 24))\n",
    "\n",
    "        ax.set_title('Original')\n",
    "        ax.imshow(original[ix])\n",
    "        ax.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "def image_checker(original, ground_truth):\n",
    "    \"\"\"Shows original images in array with their ground truth masks\"\"\"\n",
    "    for _ in range(4):\n",
    "        ix = np.random.randint(0, original.shape[0])\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 24))\n",
    "\n",
    "        ax1.set_title('Original')\n",
    "        ax1.imshow(original[ix])\n",
    "        ax1.axis('off')\n",
    "\n",
    "        ax2.set_title('Ground Truth')\n",
    "        ax2.imshow(np.squeeze(ground_truth[ix]))\n",
    "        ax2.axis('off')    \n",
    "\n",
    "        plt.subplots_adjust(wspace=.3, hspace=.3)\n",
    "        plt.show()\n",
    "\n",
    "def make_model(pretrained_model=False, model_name=model_name):\n",
    "    '''\n",
    "    Creates a new U-Net model\n",
    "    '''\n",
    "    inputs = Input((x_train.shape[1], x_train.shape[2], 3))\n",
    "    s = Lambda(lambda x: x) (inputs) # removed / 255\n",
    "\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "    c1 = Dropout(0.1) (c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "    c2 = Dropout(0.1) (c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "    c3 = Dropout(0.2) (c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "    c4 = Dropout(0.2) (c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "    c5 = Dropout(0.3) (c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "    c6 = Dropout(0.2) (c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "    c7 = Dropout(0.2) (c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "    c8 = Dropout(0.1) (c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "    c9 = Dropout(0.1) (c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "def plot_predictions(original, predicted, predicted_mask, ground_truth=None, repeat=False):\n",
    "    \"\"\"\n",
    "    Plots the original image, predicted image, mask from the predicted image, and ground truth mask.\n",
    "    ground_truth: None for testing images without masks\n",
    "    repeat: use the same first 4 images in the dataset for comparison\n",
    "    \"\"\"\n",
    "    ncols_calc = 3\n",
    "    if ground_truth is not None:\n",
    "        ncols_calc = 4\n",
    "        \n",
    "    \n",
    "    for i in range(4):\n",
    "        if repeat:\n",
    "            ix = i\n",
    "        else:\n",
    "            ix = np.random.randint(0, predicted.shape[0])\n",
    "            \n",
    "        fig, ax = plt.subplots(ncols=ncols_calc, figsize=(ncols_calc*5, 24))\n",
    "\n",
    "        ax[0].set_title('Original')\n",
    "        ax[0].imshow(original[ix])\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].set_title('Predicted')\n",
    "        ax[1].imshow(np.squeeze(predicted[ix]))\n",
    "        ax[1].axis('off')    \n",
    "\n",
    "        ax[2].set_title('Predicted Mask')\n",
    "        ax[2].imshow(np.squeeze(predicted_mask[ix]))\n",
    "        ax[2].axis('off')\n",
    "        \n",
    "        if ground_truth is not None:\n",
    "            ax[3].set_title('Ground Truth')\n",
    "            ax[3].imshow(np.squeeze(ground_truth[ix]))\n",
    "            ax[3].axis('off')\n",
    "\n",
    "        plt.subplots_adjust(wspace=.3, hspace=.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/45 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  3.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  3.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  3.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.75it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadedimages\n",
      "xlist\n",
      "4\n",
      "(400, 240, 240, 3)\n",
      "ylist\n",
      "4\n",
      "(400, 240, 240)\n",
      "stacked images\n",
      "x and y\n",
      "Shape: (1600, 240, 240, 3)\n",
      "Size: 1.03 GB\n",
      "None\n",
      "Shape: (1600, 240, 240, 1)\n",
      "Size: 0.343 GB\n",
      "None\n",
      "xtrain, etc\n",
      "Shape: (1440, 240, 240, 3)\n",
      "Size: 0.927 GB\n",
      "None\n",
      "Shape: (1440, 240, 240, 1)\n",
      "Size: 0.309 GB\n",
      "None\n",
      "Shape: (160, 240, 240, 3)\n",
      "Size: 0.103 GB\n",
      "None\n",
      "Shape: (160, 240, 240, 1)\n",
      "Size: 0.034 GB\n",
      "None\n",
      "Creating New Model\n",
      "Not using data augmentation.\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/5\n",
      "  52/1440 [>.............................] - ETA: 4:51 - loss: 0.6771 - accuracy: 0.6459"
     ]
    }
   ],
   "source": [
    "# ========================================================== SPLIT AND BATCH IMAGES\n",
    "# ========================================================== SPLIT AND BATCH THE IMAGES\n",
    "# ========================================================== SPLIT AND BATCH THE IMAGES\n",
    "\n",
    "# create batch sets of 'images_per_batch' size\n",
    "training_sets = [train_filenames[i:i + images_per_batch]\n",
    "                 for i in range(0, len(train_filenames), images_per_batch)]\n",
    "\n",
    "for batch_number, train_set in enumerate(tqdm(training_sets), start=1):\n",
    "    xlist = []\n",
    "    ylist = []\n",
    "    for name in tqdm(train_set):\n",
    "        xlist.append(load_image_as_array(name, train_image_dir, resize=True))\n",
    "        ylist.append(load_image_as_array(name, train_mask_dir, resize=True, gray=True))\n",
    "\n",
    "    print('loadedimages')\n",
    "    print('xlist')\n",
    "    print(len(xlist))\n",
    "    print(xlist[0].shape)\n",
    "    print('ylist')\n",
    "    print(len(ylist))\n",
    "    print(ylist[0].shape)\n",
    "    \n",
    "    x = (np.vstack(xlist)/255).astype(np.float32)\n",
    "    y = (np.vstack(ylist)/255).astype(np.float32)\n",
    "    y = np.expand_dims(y, axis=3)  # grayscale\n",
    "    \n",
    "    print('stacked images')\n",
    "    print('x and y')\n",
    "    print(shape_and_mem(x))\n",
    "    print(shape_and_mem(y))\n",
    "    \n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y,\n",
    "                                           random_state=77,\n",
    "                                           test_size=train_val_split_size)\n",
    "    print('xtrain, etc')\n",
    "    print(shape_and_mem(x_train))\n",
    "    print(shape_and_mem(y_train))\n",
    "    print(shape_and_mem(x_val))\n",
    "    print(shape_and_mem(y_val))\n",
    "                                                      \n",
    "    if pretrained_model or batch_number > 1:\n",
    "        print('Loading Trained Model')\n",
    "        model = load_model(model_path)\n",
    "    else:\n",
    "        print('Creating New Model')\n",
    "        model = make_model(pretrained_model=pretrained_model, model_name=model_name)\n",
    "\n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            verbose=1,\n",
    "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                            validation_steps=(x_train.shape[0] // batch_size) * train_val_split_size,\n",
    "                            callbacks=[early_stop, check_point, ValPlotCallback()])\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "\n",
    "        image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "        # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "        image_datagen.fit(x_train, augment=True, seed=seed)\n",
    "        mask_datagen.fit(y_train, augment=True, seed=seed)\n",
    "\n",
    "        image_generator = image_datagen.flow(x_train,\n",
    "                            class_mode=None,\n",
    "                            seed=seed)\n",
    "\n",
    "        mask_generator = mask_datagen.flow(y_train,\n",
    "            class_mode=None,\n",
    "            seed=seed)\n",
    "\n",
    "        # combine generators into one which yields image and masks\n",
    "        train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "        model.fit_generator(train_generator,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            verbose=1,\n",
    "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                            validation_steps=(x_train.shape[0] // batch_size) * train_val_split_size,\n",
    "                            callbacks=[early_stop, check_point, ValPlotCallback()])\n",
    "\n",
    "    model.save(model_path)\n",
    "\n",
    "# model = load_model(model_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_val_pred = model.predict(X_val, verbose=1, batch_size=batch_size)\n",
    "\n",
    "model.evaluate(x=X_val, y=y_val, batch_size=batch_size)\n",
    "\n",
    "# simple threshold to change to 1/0, mask\n",
    "X_val_pred_mask = (X_val_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "plot_predictions(original=X_val, predicted=X_val_pred, predicted_mask=X_val_pred_mask, ground_truth=y_val)\n",
    "\n",
    "X_test = [np.array(\n",
    "        image_splitter(\n",
    "            cv2.imread(TEST_IMAGE_DIR + img_name).astype(np.uint8), \n",
    "            num_col_splits=split_cols, \n",
    "            num_row_splits=split_rows,\n",
    "            resize=True,\n",
    "            resize_height=img_resize_height,\n",
    "            resize_width=img_resize_width\n",
    "        )\n",
    "    ) for img_name in tqdm(test_filenames[:10])]\n",
    "\n",
    "X_test = (np.vstack(X_test)/255).astype(np.float32)\n",
    "\n",
    "shape_and_mem(X_test)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=batch_size, verbose=1)\n",
    "\n",
    "shape_and_mem(y_pred)\n",
    "\n",
    "y_pred_mask = (y_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "plot_predictions(original=X_test, predicted=X_test_pred, predicted_mask=X_test_pred_mask)\n",
    "\n",
    "\n",
    "\n",
    "# https://www.jeremyjordan.me/evaluating-image-segmentation-models/\n",
    "\n",
    "# result = cv2.bitwise_and(test_split[0], test_split[0], mask=prediction[0])\n",
    "\n",
    "result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
