{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://www.kaggle.com/christofhenkel/keras-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# CURRENTLY WORKING WITH TENSORFLOW\n",
    "# \n",
    "# PRIORITIES:\n",
    "# 1. refactor code to better groupings\n",
    "# 2. where do the functions go\n",
    "# 3. grab validation data\n",
    "#\n",
    "#\n",
    "# If you are a potential EMPLOYER looking over my code, THANK YOU!\n",
    "# I love to hear comments and critiques about being a better programmer,\n",
    "# data engineer, and data scientist.  \n",
    "# If you found this code useful or learned something, YAY!\n",
    "# \n",
    "# LinkedIn: /in/chris-birch\n",
    "# Portfolio: www.datapointchris.com/portfolio\n",
    "# Website: www.datapointchris.com\n",
    "#\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # ======================================== FOR RUNNING ON THE MACBOOK PRO ====================\n",
    "\n",
    "### TODO ###\n",
    "# Check for MacOS environment to enable this automatically\n",
    "\n",
    "# ## DO THIS BEFORE IMPORTING KERAS OR TENSOR TO USE PLAIDML\n",
    "# import plaidml.keras\n",
    "# plaidml.keras.install_backend()\n",
    "\n",
    "# # Help MacOS be able to use Keras\n",
    "# import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "# # Gets rid of the processor warning.\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Input, BatchNormalization, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, concatenate, Concatenate, Conv2DTranspose, UpSampling2D\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from tqdm.keras import TqdmCallback\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import skimage.io\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# =========================================================================Parameters, paths and variables\n",
    "# =========================================================================Parameters, paths and variables\n",
    "\n",
    "train_image_dir = '../images/network_training/build/0/'\n",
    "train_mask_dir = '../images/network_training/mask/0/'\n",
    "test_image_dir = '../images/network_training/test/0/'\n",
    "data_dir = '../data/'\n",
    "\n",
    "train_images = glob.glob(train_image_dir + '*')\n",
    "train_filenames = [os.path.basename(x) for x in train_images]\n",
    "\n",
    "test_images = glob.glob(test_image_dir + '*')\n",
    "test_filenames = [os.path.basename(x) for x in test_images]\n",
    "\n",
    "\n",
    "# decrease this number if running out of memory\n",
    "# works with 4 on 11GB GPU\n",
    "images_per_batch = 4\n",
    "\n",
    "# val split from training set\n",
    "train_val_split_size = .1\n",
    "\n",
    "seed = 77\n",
    "\n",
    "\n",
    "# ======Image Splitter ====== #\n",
    "\n",
    "split_rows = 20\n",
    "split_cols = 20\n",
    "resize = True\n",
    "image_resize_width = 4800\n",
    "image_resize_height = 4800\n",
    "\n",
    "\n",
    "# ==================================== MODEL PARAMS ==================================== #\n",
    "epochs = 5\n",
    "batch_size = 1\n",
    "\n",
    "pretrained_model = False\n",
    "model_name = 'datagenmodel'\n",
    "model_path = os.path.join(data_dir, model_name + '.h5')\n",
    "plot_epoch_val_images = True\n",
    "\n",
    "# ==================== Callbacks ==================== #\n",
    "early_stop = EarlyStopping(patience=5, verbose=1)\n",
    "check_point = ModelCheckpoint(os.path.join(data_dir, model_name + '.hdf5'),\n",
    "                              save_best_only=True,verbose=1)\n",
    "tensor_board = TensorBoard(log_dir='../logs/tensorboard/', histogram_freq=1, \n",
    "                            write_graph=True, write_grads=False, \n",
    "                            write_images=True, embeddings_freq=1, update_freq='batch')\n",
    "\n",
    "# ==================== Fit Params ==================== #\n",
    "model_fit_params = dict(batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        verbose=1,\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        validation_steps=(x_train.shape[0] // batch_size) * train_val_split_size,\n",
    "                        callbacks=[early_stop, check_point, tensor_board, ValPlotCallback()])\n",
    "                        \n",
    "# ==================== Data Augmentation ==================== #                        \n",
    "data_augmentation = True\n",
    "datagen_args = dict(featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                             samplewise_center=False,  # set each sample mean to 0\n",
    "                             featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                             samplewise_std_normalization=False,  # divide each input by its std\n",
    "                             zca_whitening=False,  # apply ZCA whitening\n",
    "                             zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "                             # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                             rotation_range=0,\n",
    "                             # randomly shift images horizontally (fraction of total width)\n",
    "                             width_shift_range=0.1,\n",
    "                             # randomly shift images vertically (fraction of total height)\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.,  # set range for random shear\n",
    "                             zoom_range=0.,  # set range for random zoom\n",
    "                             channel_shift_range=0.,  # set range for random channel shifts\n",
    "                             # set mode for filling points outside the input boundaries\n",
    "                             fill_mode='nearest',\n",
    "                             cval=0.,  # value used for fill_mode = \"constant\"\n",
    "                             horizontal_flip=True,  # randomly flip images\n",
    "                             vertical_flip=False,  # randomly flip images\n",
    "                             # set rescaling factor (applied before any other transformation)\n",
    "                             rescale=None,\n",
    "                             # set function that will be applied on each input\n",
    "                             preprocessing_function=None,\n",
    "                             # image data format, either \"channels_first\" or \"channels_last\"\n",
    "                             data_format='channels_last',\n",
    "                             # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "                             validation_split=0.0)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValPlotCallback(Callback):\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print('VALIDATION IMAGES')\n",
    "        X_val_pred = model.predict(X_val, verbose=1, batch_size=batch_size)\n",
    "        X_val_pred_mask = (X_val_pred > 0.5).astype(np.uint8)\n",
    "        plot_predictions(original=X_val,\n",
    "                         predicted=X_val_pred,\n",
    "                         predicted_mask=X_val_pred_mask,\n",
    "                         ground_truth=y_val,\n",
    "                         repeat=True)\n",
    "\n",
    "def load_image_as_array(image_name, image_dir, gray=False, resize=False):\n",
    "    \"\"\"\n",
    "    Loads and splits an image\n",
    "    Returns numpy array\n",
    "    \"\"\"\n",
    "    if gray is False:\n",
    "        image = cv2.imread(image_dir + image_name).astype(np.uint8)\n",
    "    else:\n",
    "        image = cv2.imread(image_dir + image_name, 0).astype(np.uint8)\n",
    "\n",
    "    image_as_array = image_splitter(image,\n",
    "                                 num_col_splits=split_cols,\n",
    "                                 num_row_splits=split_rows,\n",
    "                                 resize=resize,\n",
    "                                 resize_height=image_resize_height,\n",
    "                                 resize_width=image_resize_width)\n",
    "\n",
    "    return image_as_array\n",
    "\n",
    "def shape_and_mem(array):\n",
    "    \"\"\"Prints the shape and memory size of an array\"\"\"\n",
    "    print(f'Shape: {array.shape}')\n",
    "    print(f'Size: {round(array.itemsize * array.size / 1024 / 1024 / 1024, 3)} GB')\n",
    "\n",
    "def image_splitter(image, num_col_splits, num_row_splits, resize=False, resize_width=None, resize_height=None):\n",
    "    \"\"\"\n",
    "    Splits an image into 'num_col_splits' X 'num_row_splits'\n",
    "    Resize by setting resize=True and specifying 'resize_width' and 'resize_height'\n",
    "    Returns array of images arranged from left -> right, top -> bottom\n",
    "    \"\"\"\n",
    "    if resize:\n",
    "        image = cv2.resize(image, (resize_width, resize_height))\n",
    "    \n",
    "    width = image.shape[0] \n",
    "    height = image.shape[1]\n",
    "    imglist = []\n",
    "\n",
    "    for startpoint in np.linspace(0,width,num_col_splits, endpoint=False):\n",
    "        endpoint=startpoint + (width / num_col_splits)\n",
    "\n",
    "        for startp2 in np.linspace(0,height,num_row_splits, endpoint=False):\n",
    "            endp2=startp2 + (height / num_row_splits)\n",
    "\n",
    "            imglist.append(image[int(startp2):int(endp2), int(startpoint):int(endpoint)]\n",
    "                        )\n",
    "    return np.array(imglist)\n",
    "\n",
    "def image_tester(original):\n",
    "    \"\"\"Shows original images in array\"\"\"\n",
    "    for _ in range(4):\n",
    "        ix = np.random.randint(0, original.shape[0])\n",
    "        fig, ax = plt.subplots(figsize=(10, 24))\n",
    "\n",
    "        ax.set_title('Original')\n",
    "        ax.imshow(original[ix])\n",
    "        ax.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "def image_checker(original, ground_truth):\n",
    "    \"\"\"Shows original images in array with their ground truth masks\"\"\"\n",
    "    for _ in range(4):\n",
    "        ix = np.random.randint(0, original.shape[0])\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 24))\n",
    "\n",
    "        ax1.set_title('Original')\n",
    "        ax1.imshow(original[ix])\n",
    "        ax1.axis('off')\n",
    "\n",
    "        ax2.set_title('Ground Truth')\n",
    "        ax2.imshow(np.squeeze(ground_truth[ix]))\n",
    "        ax2.axis('off')    \n",
    "\n",
    "        plt.subplots_adjust(wspace=.3, hspace=.3)\n",
    "        plt.show()\n",
    "\n",
    "def make_model(pretrained_model=False, model_name=model_name):\n",
    "    '''\n",
    "    Creates a new U-Net model\n",
    "    '''\n",
    "    inputs = Input((x_train.shape[1], x_train.shape[2], 3))\n",
    "    s = Lambda(lambda x: x) (inputs) # removed / 255\n",
    "\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "    c1 = Dropout(0.1) (c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "    c2 = Dropout(0.1) (c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "    c3 = Dropout(0.2) (c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "    c4 = Dropout(0.2) (c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "    c5 = Dropout(0.3) (c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "    c6 = Dropout(0.2) (c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "    c7 = Dropout(0.2) (c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "    c8 = Dropout(0.1) (c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "    c9 = Dropout(0.1) (c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "def plot_predictions(original, predicted, predicted_mask, ground_truth=None, repeat=False):\n",
    "    \"\"\"\n",
    "    Plots the original image, predicted image, mask from the predicted image, and ground truth mask.\n",
    "    ground_truth: None for testing images without masks\n",
    "    repeat: use the same first 4 images in the dataset for comparison\n",
    "    \"\"\"\n",
    "    ncols_calc = 3\n",
    "    if ground_truth is not None:\n",
    "        ncols_calc = 4\n",
    "        \n",
    "    \n",
    "    for i in range(4):\n",
    "        if repeat:\n",
    "            ix = i\n",
    "        else:\n",
    "            ix = np.random.randint(0, predicted.shape[0])\n",
    "            \n",
    "        fig, ax = plt.subplots(ncols=ncols_calc, figsize=(ncols_calc*5, 24))\n",
    "\n",
    "        ax[0].set_title('Original')\n",
    "        ax[0].imshow(original[ix])\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].set_title('Predicted')\n",
    "        ax[1].imshow(np.squeeze(predicted[ix]))\n",
    "        ax[1].axis('off')    \n",
    "\n",
    "        ax[2].set_title('Predicted Mask')\n",
    "        ax[2].imshow(np.squeeze(predicted_mask[ix]))\n",
    "        ax[2].axis('off')\n",
    "        \n",
    "        if ground_truth is not None:\n",
    "            ax[3].set_title('Ground Truth')\n",
    "            ax[3].imshow(np.squeeze(ground_truth[ix]))\n",
    "            ax[3].axis('off')\n",
    "\n",
    "        plt.subplots_adjust(wspace=.3, hspace=.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  2.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:01<00:00,  2.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadedimages\n",
      "xlist\n",
      "4\n",
      "(400, 240, 240, 3)\n",
      "ylist\n",
      "4\n",
      "(400, 240, 240)\n",
      "stacked images\n",
      "x and y\n",
      "Shape: (1600, 240, 240, 3)\n",
      "Size: 1.03 GB\n",
      "None\n",
      "Shape: (1600, 240, 240, 1)\n",
      "Size: 0.343 GB\n",
      "None\n",
      "xtrain, etc\n",
      "Shape: (1440, 240, 240, 3)\n",
      "Size: 0.927 GB\n",
      "None\n",
      "Shape: (1440, 240, 240, 1)\n",
      "Size: 0.309 GB\n",
      "None\n",
      "Shape: (160, 240, 240, 3)\n",
      "Size: 0.103 GB\n",
      "None\n",
      "Shape: (160, 240, 240, 1)\n",
      "Size: 0.034 GB\n",
      "None\n",
      "Creating New Model\n",
      "Using real-time data augmentation.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1440 steps, validate on 160 samples\n",
      "Epoch 1/5\n",
      "  12/1440 [..............................] - ETA: 1:52:16 - loss: 0.6886 - accuracy: 0.6332WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  12/1440 [..............................] - ETA: 1:52:41 - loss: 0.6886 - accuracy: 0.6332VALIDATION IMAGES\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_start\u001b[0;34m(self, model, callbacks, use_samples, verbose, mode)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_successful_loop_finish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-68a34d24348c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m                       total_epochs=1)\n\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 397\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_start\u001b[0;34m(self, model, callbacks, use_samples, verbose, mode)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m       \u001b[0;31m# End of all epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf_contextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_end_hook\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;34m\"\"\"Helper function for on_{train|test|predict}_end methods.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \"\"\"\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-07dd38027371>\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VALIDATION IMAGES'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mX_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mX_val_pred_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         plot_predictions(original=X_val,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "# ========================================================== SPLIT AND BATCH IMAGES\n",
    "# ========================================================== SPLIT AND BATCH THE IMAGES\n",
    "# ========================================================== SPLIT AND BATCH THE IMAGES\n",
    "\n",
    "# create batch sets of 'images_per_batch' size\n",
    "training_sets = [train_filenames[i:i + images_per_batch]\n",
    "                 for i in range(0, len(train_filenames), images_per_batch)]\n",
    "\n",
    "for batch_number, train_set in enumerate(tqdm(training_sets), start=1):\n",
    "    xlist = []\n",
    "    ylist = []\n",
    "    for name in tqdm(train_set):\n",
    "        xlist.append(load_image_as_array(name, train_image_dir, resize=True))\n",
    "        ylist.append(load_image_as_array(\n",
    "            name, train_mask_dir, resize=True, gray=True))\n",
    "\n",
    "    print('loadedimages')\n",
    "    print('xlist')\n",
    "    print(len(xlist))\n",
    "    print(xlist[0].shape)\n",
    "    print('ylist')\n",
    "    print(len(ylist))\n",
    "    print(ylist[0].shape)\n",
    "\n",
    "    x = (np.vstack(xlist)/255).astype(np.float32)\n",
    "    y = (np.vstack(ylist)/255).astype(np.float32)\n",
    "    y = np.expand_dims(y, axis=3)  # grayscale\n",
    "\n",
    "    print('stacked images')\n",
    "    print('x and y')\n",
    "    print(shape_and_mem(x))\n",
    "    print(shape_and_mem(y))\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y,\n",
    "                                                      random_state=77,\n",
    "                                                      test_size=train_val_split_size)\n",
    "    print('xtrain, etc')\n",
    "    print(shape_and_mem(x_train))\n",
    "    print(shape_and_mem(y_train))\n",
    "    print(shape_and_mem(x_val))\n",
    "    print(shape_and_mem(y_val))\n",
    "\n",
    "    if pretrained_model or batch_number > 1:\n",
    "        print('Loading Trained Model')\n",
    "        model = load_model(model_path)\n",
    "    else:\n",
    "        print('Creating New Model')\n",
    "        model = make_model(pretrained_model=pretrained_model,\n",
    "                           model_name=model_name)\n",
    "\n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        history = model.fit(x_train, y_train, **model_fit_params)\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "\n",
    "        image_datagen = ImageDataGenerator(**datagen_args)\n",
    "        mask_datagen = ImageDataGenerator(**datagen_args)\n",
    "\n",
    "        # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "        image_datagen.fit(x_train, augment=True, seed=seed)\n",
    "        mask_datagen.fit(y_train, augment=True, seed=seed)\n",
    "\n",
    "        image_generator = image_datagen.flow(x_train,\n",
    "                                             save_to_dir='../images/augmented/images/',\n",
    "                                             seed=seed)\n",
    "\n",
    "        mask_generator = mask_datagen.flow(y_train,\n",
    "                                           save_to_dir='../images/augmented/masks/',\n",
    "                                           seed=seed)\n",
    "### NOTE ###\n",
    "# Can I use the validation setting on the image generators and get rid of the train/test split\n",
    "# then I can feed my images in as generators to the generators and skip the loop\n",
    "        \n",
    "        # combine generators into one which yields image and masks\n",
    "        train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "        model.fit(train_generator, **model_fit_params)\n",
    "\n",
    "    model.save(model_path)\n",
    "\n",
    "# model = load_model(model_path)\n",
    "\n",
    "\n",
    "x_val_pred = model.predict(x_val, verbose=1, batch_size=batch_size)\n",
    "\n",
    "model.evaluate(x=x_val, y=y_val, batch_size=batch_size)\n",
    "\n",
    "# simple threshold to change to 1/0, mask\n",
    "x_val_pred_mask = (x_val_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "plot_predictions(original=_val, predicted=_val_pred,\n",
    "                 predicted_mask=x_val_pred_mask, ground_truth=y_val)\n",
    "\n",
    "x_test = [np.array(\n",
    "    image_splitter(\n",
    "        cv2.imread(test_image_dir + img_name).astype(np.uint8),\n",
    "        num_col_splits=split_cols,\n",
    "        num_row_splits=split_rows,\n",
    "        resize=resize,\n",
    "        resize_height=img_resize_height,\n",
    "        resize_width=img_resize_width\n",
    "    )\n",
    ") for img_name in tqdm(test_filenames[:10])]\n",
    "\n",
    "x_test = (np.vstack(x_test)/255).astype(np.float32)\n",
    "\n",
    "shape_and_mem(X_test)\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow(x_test, seed=seed)\n",
    "\n",
    "y_pred = model.predict_generator(test_generator, batch_size=batch_size, verbose=1)\n",
    "\n",
    "shape_and_mem(y_pred)\n",
    "\n",
    "y_pred_mask = (y_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "plot_predictions(original=X_test, predicted=X_test_pred,\n",
    "                 predicted_mask=X_test_pred_mask)\n",
    "\n",
    "\n",
    "# https://www.jeremyjordan.me/evaluating-image-segmentation-models/\n",
    "\n",
    "# result = cv2.bitwise_and(test_split[0], test_split[0], mask=prediction[0])\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
